{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook for processing raw MMWHS data to HighRes data and corresponding segmentations\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import nibabel as nib\n",
    "from process_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes directories for MMWHS dataset\n",
    "\n",
    "if not os.path.exists('./MMWHS'):\n",
    "    os.makedirs('./MMWHS')\n",
    "    \n",
    "if not os.path.exists('./MMWHS/ims'):\n",
    "    os.makedirs('./MMWHS/ims')\n",
    "    \n",
    "if not os.path.exists('./MMWHS/segmentations'):\n",
    "    os.makedirs('./MMWHS/segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads segmentation data\n",
    "#Must split downloaded MMWHS data into './MMWHS/ims' and './MMWHS/segmentations' folders\n",
    "def load_data_samples_seg(no,filename=\"./MMWHS/segmentations/*.nii.gz\"):\n",
    "\tclean_ims = []\n",
    "\tpix_dimensions = []\n",
    "\tif not os.path.exists(\"./MMWHS/segmentations\"):\n",
    "\t\traise Exception(\"Error with file path.\")\n",
    "\telse:\n",
    "\t\tfiles = glob.glob(filename)\n",
    "\t\tfiles = sorted(files)\n",
    "\t\tfor i in range(1):\n",
    "\t\t\ti = no\n",
    "\t\t\t\n",
    "\t\t\tnii_img  = nib.load(files[i])\n",
    "\n",
    "\t\t\tnii_data = nii_img.get_fdata()\n",
    "\n",
    "\t\t\tif nii_data.shape[1] == 512 and nii_data.shape[0] == 512:\n",
    "\t\t\t\tclean_ims.append(nii_data[:,::-1,:])\n",
    "\t\t\telse:\n",
    "\t\t\t\tclean_ims.append(np.transpose(nii_data[:,::-1,::-1],[2,1,0]))\n",
    "\t\t\t\n",
    "\t\t\tpix_dimensions.append(nii_img.header['pixdim'])\n",
    "\n",
    "\t\treturn clean_ims, pix_dimensions\n",
    "\n",
    "#Loads image data\n",
    "def load_data_samples(no,filename=\"./MMWHS/ims/*.nii.gz\"):\n",
    "\tclean_ims = []\n",
    "\tpix_dimensions = []\n",
    "\torientations = []\n",
    "\tif not os.path.exists(\"./MMWHS/ims\"):\n",
    "\t\traise Exception(\"Error with file path.\")\n",
    "\telse:\n",
    "\t\tfiles = glob.glob(filename)\n",
    "\t\tfiles = sorted(files)\n",
    "\t\tfor i in range(1):\n",
    "\t\t\ti=no\n",
    "\t\t\t\n",
    "\t\t\tnii_img  = nib.load(files[i])\n",
    "\n",
    "\t\t\tnii_data = nii_img.get_fdata()\n",
    "\t\t\tif nii_data.shape[1] == 512 and nii_data.shape[0] == 512:\n",
    "\t\t\t\tclean_ims.append(nii_data[:,::-1,:])\n",
    "\t\t\telse:\n",
    "\t\t\t\tclean_ims.append(np.transpose(nii_data[:,::-1,::-1],[2,1,0]))\n",
    "\n",
    "\t\t\taffine = nii_img.affine\n",
    "\t\t\torientation = nib.aff2axcodes(affine)\n",
    "\t\t\torientations.append(''.join(orientation))\n",
    "\t\t\t\n",
    "\t\t\tpix_dimensions.append(nii_img.header['pixdim'])\n",
    "\t\t\t\n",
    "\n",
    "\t\treturn clean_ims, pix_dimensions , orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes directory to store data\n",
    "if not os.path.exists('./seg_data'):\n",
    "    os.makedirs('./seg_data')\n",
    "\n",
    "#Set number of MMWHS datasets to process\n",
    "MMWHS_No = 1\n",
    "\n",
    "#Set output data size\n",
    "z=112\n",
    "x=256\n",
    "y=128\n",
    "\n",
    "unique_values = [500,600,420,550,820,850,205,0] # [LV,RV,LA,RA,Aorta,PA,Myocardium,Background]\n",
    "\n",
    "# Loop for data generation\n",
    "for pat in tqdm(range(MMWHS_No)):\n",
    "    \n",
    "    # Loading data\n",
    "\tim_1,pix_dimensions_1 , orientations = load_data_samples(pat)  \n",
    "\tseg_1,pix_dimensions_1= load_data_samples_seg(pat)  \n",
    "\n",
    "\timage = np.expand_dims(im_1[0],-1)\n",
    "\tsegmentation = np.expand_dims(seg_1[0],-1)\n",
    "\tdata = np.concatenate((image,segmentation),-1)\n",
    "\n",
    "\tsegmentation = data[...,-1]\n",
    "\n",
    "\tsegmentations = []\n",
    "\tfor i in range(6):\n",
    "\t\tseg = segmentation==unique_values[i]\n",
    "\t\tsegmentations.append(seg)\n",
    "\tsegmentations = np.array(segmentations)\n",
    "\tsegmentations = np.transpose(segmentations,(1,2,3,0))\n",
    "\n",
    "\ttemp = np.concatenate((image,segmentations),-1)\n",
    "\n",
    "\t#Fixing orientation for all volumes \n",
    "\tif orientations[pat] == 'LSP':\n",
    "\t\tsf_x = pix_dimensions_1[pat][1]\n",
    "\t\tsf_y = pix_dimensions_1[pat][2]\n",
    "\t\tsf_z = pix_dimensions_1[pat][3]\n",
    "\telse:\n",
    "\t\tsf_x = pix_dimensions_1[pat][3]\n",
    "\t\tsf_y = pix_dimensions_1[pat][2]\n",
    "\t\tsf_z = pix_dimensions_1[pat][1]\n",
    "  \n",
    "\t#Rescaling to 1.5mm isotropic data\n",
    "\trescaled_temp = []\n",
    "\tfor channel in range(temp.shape[-1]):\n",
    "\t\trescaled = skimage.transform.rescale(temp[...,channel], scale=[sf_x/1.5,sf_y/1.5,sf_z/1.5], order=3,anti_aliasing= True,preserve_range=True, mode ='constant',cval=0)\n",
    "\t\trescaled_temp.append(rescaled)\n",
    "  \n",
    "\trescaled = np.array(rescaled_temp)\n",
    "\trescaled = np.transpose(rescaled,(1,2,3,0))\n",
    "\n",
    "\t#Threshold to keep masks binary\n",
    "\trounded_data = []\n",
    "\tfor i in range(6):\n",
    "\t\tint_seg = rescaled[:,:,:,i+1] > 0.2\n",
    "\t\trounded_data.append(int_seg)\n",
    "\t\n",
    "\trounded_data = np.array(rounded_data)\n",
    "\trounded_data = np.transpose(rounded_data,(1,2,3,0))\n",
    "\ttemp = np.concatenate((rescaled[...,:1],rounded_data),-1)\n",
    "\n",
    "\t#Crop or pad to desired shape\n",
    "\ty_mid = find_com(temp[int(np.rint(temp.shape[0]/2)),:,:,0])[0]\n",
    "\tz_com = find_com(temp[:,:,int(y_mid),0])[1]\n",
    "\tcropped_vol= []\n",
    "\tseg_cropped_vol = []\n",
    "\t\n",
    "\tstart = z_com - z/2\n",
    "\tempty_slice = np.zeros((256,128,8))\n",
    "\tempty_slice_1 = np.zeros((256,128,1))\n",
    "\tif start + z > temp.shape[0]:\n",
    "\t\tstart = temp.shape[0]-z\n",
    "\t\tmissing = 0\n",
    "\tif start < 0:\n",
    "\t\tstart = 0\n",
    "\t\tmissing = z - temp.shape[0]\n",
    "\telse:\n",
    "\t\tmissing = 0\n",
    "\n",
    "\tif missing!=0:\n",
    "\t\tpad_number_1 = int(np.rint(missing/2))\n",
    "\t\tfor j in range(pad_number_1):\n",
    "\t\t\tcropped_vol.append(empty_slice_1)\n",
    "\t\t\tseg_cropped_vol.append(empty_slice)\n",
    "\tfor i in range(temp.shape[0]):\n",
    "\t\tslice = temp[i,...,:1]\n",
    "\t\tseg_slice = temp[i,...,1:]\n",
    "\t\tif start <= i < start+z:\n",
    "\t\t\tpad_x = x-slice.shape[0]\n",
    "\t\t\tpad_y = y - slice.shape[1]\n",
    "\t\t\tif pad_x > 0 and pad_y >0:\n",
    "\t\t\t\tslice = np.pad(slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='constant')\n",
    "\t\t\telif pad_x > 0:\n",
    "\t\t\t\tslice = np.pad(slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(0,0),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(0,0),(0,0)),mode='constant')\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\telif pad_y > 0:\n",
    "\t\t\t\tslice = np.pad(slice,((0,0),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((0,0),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='constant')\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\telse:\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\tcropped_vol.append(slice)\n",
    "\t\t\tseg_cropped_vol.append(seg_slice)\n",
    "\tif missing!=0:\n",
    "\t\tpad_number_2 = missing - pad_number_1\n",
    "\t\tfor j in range(pad_number_2):\n",
    "\t\t\tcropped_vol.append(empty_slice_1)\n",
    "\t\t\tseg_cropped_vol.append(empty_slice)\n",
    "\n",
    "\tcropped_vol_1 = np.array(cropped_vol)\n",
    "\tseg_cropped_vol_1 = np.array(seg_cropped_vol)\n",
    "\n",
    "\tcropped_vol_1 = apply_clahe(cropped_vol_1) #CLAHE\n",
    "\n",
    "\tcropped_vol_fin = np.concatenate((cropped_vol_1,seg_cropped_vol_1),-1)\n",
    " \n",
    "\tnp.save(f'./seg_data/High_Res_MMWHS_NoAug_{pat}.npy', cropped_vol_fin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
