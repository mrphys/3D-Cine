{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:39:23.533909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-13 14:39:23.678059: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-13 14:39:23.734772: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Notebook for processing data into 3D cine + segmentations\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow_mri as tfmri\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import pydicom as dicom\n",
    "from unet3plusnew import *\n",
    "from custom_unet_code import *\n",
    "from process_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes directories for processed data\n",
    "\n",
    "if not os.path.exists('./processed_data'):\n",
    "    os.makedirs('./processed_data')\n",
    "    \n",
    "if not os.path.exists('./processed_data/3D_cine'):\n",
    "    os.makedirs('./processed_data/3D_cine')\n",
    "    \n",
    "if not os.path.exists('./processed_data/seg_ML'):\n",
    "    os.makedirs('./processed_data/seg_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applies debanding model to any number of slices\n",
    "def apply_debanding_model(input_im,frames =32):\n",
    "\n",
    "    debanding_model = \"./models_final/Deband_model\"\n",
    "    debanding = tf.keras.models.load_model(debanding_model, compile=False)\n",
    "    weights = debanding.get_weights()\n",
    "\n",
    "    inputs = tf.keras.Input(shape = [None,None,None,1])\n",
    "    unet = tfmri.models.UNet3D([32,64,128], kernel_size=3, out_channels=1,use_global_residual=False) \n",
    "    DB = unet(inputs)\n",
    "    de_banding_model = tf.keras.Model(inputs = inputs, outputs = DB)\n",
    "    de_banding_model.set_weights(weights)\n",
    "\n",
    "    de_banded = []\n",
    "    for i in range(frames):\n",
    "        temp = de_banding_model.predict(tf.expand_dims(tf.expand_dims(input_im[i],0),-1),verbose = 0)\n",
    "        de_banded.append(temp)\n",
    "\n",
    "    return de_banded\n",
    "\n",
    "#Function that applies deformations to 28 slice data\n",
    "def deformation_28(x):\n",
    "\n",
    "    sagittal_deformed = []\n",
    "\n",
    "    for i in range(28):\n",
    "        \n",
    "        input_img = tf.expand_dims(x[0][0,i,:,:], -1) \n",
    "        dy = tf.expand_dims(tf.expand_dims(x[1][0,i,:,:], -1),0)\n",
    "        dx = tf.expand_dims(tf.expand_dims(x[2][0,i,:,:], -1),0)\n",
    "        \n",
    "        displacement = tf.concat((dy[0,...],dx[0,...]), axis=-1)\n",
    "\n",
    "        img = tf.image.convert_image_dtype(tf.expand_dims(input_img, 0), tf.dtypes.float32)\n",
    "        displacement = tf.image.convert_image_dtype(displacement, tf.dtypes.float32)\n",
    "        dense_img_warp = tfa.image.dense_image_warp(img, displacement)\n",
    "        im_deformed = tf.squeeze(dense_img_warp, 0)\n",
    "        sagittal_deformed.append(im_deformed)\n",
    "\n",
    "    sagittal_deformed = tf.image.convert_image_dtype(sagittal_deformed, tf.dtypes.float32)\n",
    "    sagittal_deformed = tf.expand_dims(sagittal_deformed,axis= 0)\n",
    "\n",
    "    return sagittal_deformed\n",
    "\n",
    "#Applies respiratory correction model\n",
    "def apply_resp_model_28(input_im,frames = 32):\n",
    "\n",
    "    inputs = tf.keras.Input(shape = [None,256,128,1])\n",
    "    unet = build_3d_unet_resp([None,256,128,1],2) # Acts as aa deformation field generator\n",
    "    deformation_fields = unet(inputs) # Outputs the deformation fields\n",
    "    lambda_deformation = tf.keras.layers.Lambda(deformation_28)\n",
    "    out_2 = lambda_deformation([inputs[:,:,:,:,0],deformation_fields[:,:,:,:,0],deformation_fields[:,:,:,:,1]]) # Outputs the deformed volume\n",
    "    outputs  = [deformation_fields,out_2] \n",
    "    complete_model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    complete_model.load_weights('./models_final/Resp_Correction_model/variables/variables')\n",
    "\n",
    "    resp_corrected = []\n",
    "    deformations = []\n",
    "    for i in range(frames):\n",
    "\n",
    "        def_fields, resp_cor = complete_model.predict(input_im[i][:,:,:,:,:],verbose=0)\n",
    "        resp_corrected.append(resp_cor)\n",
    "        deformations.append(def_fields)\n",
    "\n",
    "    return deformations, resp_corrected\n",
    "\n",
    "#Applies super resolution model\n",
    "def apply_SR_model(input_im,frames = 32):\n",
    "    E2E_model = \"./models_final/E2E_SR_model\"\n",
    "    E2E = tf.keras.models.load_model(E2E_model, compile=False)\n",
    "    weights = E2E.get_weights()\n",
    "    sr_weights = weights[22:]\n",
    "\n",
    "    inputs = tf.keras.Input(shape = [None,None,None,1])\n",
    "    SR_model = build_3d_unet(input_shape=(None, None,None,1), num_classes=1)\n",
    "    SR = SR_model(inputs)\n",
    "    SR_model_done = tf.keras.Model(inputs = inputs, outputs = SR)\n",
    "    SR_model_done.set_weights(sr_weights)\n",
    "\n",
    "    super_resed = []\n",
    "    for i in range(frames):\n",
    "        super_resed.append(SR_model_done.predict(input_im[i],verbose=0))\n",
    "\n",
    "    return super_resed\n",
    "\n",
    "#Applies segmentation model\n",
    "def apply_seg_model(input_im,frames=32):\n",
    "\n",
    "    seg_model = \"./models_final/Segmentation_model\"\n",
    "    seg= tf.keras.models.load_model(seg_model, compile=False)\n",
    "    weights = seg.get_weights()\n",
    "\n",
    "    number_of_seg = 7\n",
    "\n",
    "    inputs = tf.keras.Input(shape = [None,None,None,1])\n",
    "\n",
    "    unet3 = unet3plus(inputs,\n",
    "                 filters=[32,64,128],\n",
    "                 rank = 3,  # dimension\n",
    "                 out_channels = number_of_seg,\n",
    "                 add_dropout = 0, # 1 or 0 to add dropout\n",
    "                 dropout_rate = 0.3,\n",
    "                 #base_filters = 32,\n",
    "                 kernel_size = 3,\n",
    "                 encoder_block_depth= 2,\n",
    "                 decoder_block_depth = 1,\n",
    "                 pool_size = 2, # This can be either a tuple or int for same pooling across dims\n",
    "                 skip_type = 'encoder',\n",
    "                 batch_norm = 1,\n",
    "                 skip_batch_norm = 1,\n",
    "                 activation = tf.keras.layers.LeakyReLU(alpha =0.01),#tf.keras.layers.LeakyReLU(alpha =0.01),#'relu',\n",
    "                 out_activation = 'softmax',\n",
    "                 CGM = 0,\n",
    "                 deep_supervision = 0) # 1 or 0 to add deep_supervision\n",
    "\n",
    "    seg_model_done = tf.keras.Model(inputs = inputs, outputs = unet3.outputs())\n",
    "\n",
    "    seg_model_done.set_weights(weights)\n",
    "\n",
    "    seg = []\n",
    "    for i in range(frames):\n",
    "        seg.append(get_one_hot(seg_model_done.predict(input_im[i],verbose=0),number_of_seg))\n",
    "\n",
    "    return seg\n",
    "\n",
    "#Reads in example RT sagittal stack\n",
    "def load_data_samples(number_of_scans = 32):\n",
    "    sag_volumes = []\n",
    "    filename=f\"./raw_data/RT_Stack/*\"\n",
    "    if not os.path.exists(f\"./raw_data/RT_Stack/\"):\n",
    "        raise Exception(\"Error with file path.\")\n",
    "    else:\n",
    "        for i in range(number_of_scans):\n",
    "            \n",
    "            clean_ims_1 = []\n",
    "            locations_1 = []\n",
    "            test = sorted(glob.glob(filename))\n",
    "            for folder in test:\n",
    "                for file in tqdm(glob.glob(folder+'/*'), disable=True):\n",
    "                    ds = dicom.dcmread(file)\n",
    "\n",
    "                    if ds.InstanceNumber == i+1:\n",
    "                        locations_1.append(ds.SliceLocation)\n",
    "                        clean_ims_1.append(ds.pixel_array)\n",
    "            \n",
    "            clean_ims_1 = [x for _,x in sorted(zip(locations_1,clean_ims_1))]\n",
    "            sag_volumes.append(clean_ims_1)\n",
    "\n",
    "    return np.array(sag_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 32 #Time steps of cine data\n",
    "sag_vols = load_data_samples(number_of_scans=time_steps) #Loads in data\n",
    "sag_vols_cropped = []\n",
    "\n",
    "print('Cropping...')\n",
    "sag_vols = np.array(sag_vols)\n",
    "for j in range(time_steps):\n",
    "    sag_cropped = []\n",
    "    for i in range(sag_vols.shape[1]):    \n",
    "        sag_cropped.append(resize(sag_vols[j,i,:,:],256,128))\n",
    "    sag_cropped = np.dstack(sag_cropped)\n",
    "    sag_cropped = np.swapaxes(sag_cropped,0,1)\n",
    "    sag_cropped = np.swapaxes(sag_cropped,0,2)\n",
    "    sag_vols_cropped.append(sag_cropped)\n",
    "\n",
    "sag_vols_cropped = norm(sag_vols_cropped)\n",
    "\n",
    "print('De-banding...')\n",
    "debanded = apply_debanding_model(sag_vols_cropped,frames=time_steps)\n",
    "debanded = norm(debanded)\n",
    "\n",
    "print('Resp-correction...')\n",
    "def_fields , resp_cor = apply_resp_model_28(debanded,frames=time_steps)\n",
    "resp_cor = norm(resp_cor)\n",
    "\n",
    "print('SR...')\n",
    "super_resed_E2E = apply_SR_model(resp_cor,frames=time_steps)\n",
    "super_resed_E2E = norm(super_resed_E2E)\n",
    "\n",
    "for i in range(time_steps):\n",
    "    np.save(f'./processed_data/3D_cine/3D_cine_{i}.npy',super_resed_E2E[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Segmenting...')\n",
    "\n",
    "clahe = []\n",
    "for i in range(time_steps):\n",
    "    sr = np.load(f'./processed_data/3D_cine/3D_cine_{i}.npy')\n",
    "    \n",
    "    clahe.append(tf.expand_dims(tf.expand_dims(apply_clahe(sr[0,:,:,:,0]),-1),0))\n",
    "\n",
    "E2E_seg = apply_seg_model(clahe)\n",
    "\n",
    "for i in range(time_steps):\n",
    "    seg_rm_add = keep_largest_component_add(E2E_seg[i][0,...])\n",
    "\n",
    "    final_seg = np.zeros_like(E2E_seg[0][...,0])\n",
    "    for j in range(6):\n",
    "        final_seg = final_seg + seg_rm_add[...,j+1]*(j+1)\n",
    "    np.save(f'./processed_data/seg_ML/seg_{i}.npy',final_seg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
