{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook for processing raw HVSMR data into HighRes volume and corresponding segmentations\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import nibabel as nib\n",
    "from process_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes directory for HVSMR dataset\n",
    "\n",
    "if not os.path.exists('./HVSMR'):\n",
    "    os.makedirs('./HVSMR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads images and segmentations\n",
    "#Must put downloaded HVSMR data into './HVSMR' folder\n",
    "def load_data_samples(pat_no, filename=\"./HVSMR/*.nii.gz\"):\n",
    "\tclean_ims = []\n",
    "\tpix_dimensions = []\n",
    "\tif not os.path.exists(\"./HVSMR\"):\n",
    "\t\traise Exception(\"Error with file path.\")\n",
    "\telse:\n",
    "\t\tfiles = glob.glob(filename)\n",
    "\t\tfiles = sorted(files)\n",
    "\n",
    "\t\tfor i in range(1):\n",
    "\t\t\tpat = []\n",
    "\t\t\tfor j in range(2):\n",
    "       \n",
    "\t\t\t\ti=pat_no\n",
    "\n",
    "\t\t\t\tnii_img  = nib.load(files[i*3 + j])\n",
    "\n",
    "\t\t\t\tnii_data = nii_img.get_fdata()\n",
    "\n",
    "\t\t\t\tpat.append(np.transpose(nii_data[:,:,:],(2,1,0)))\n",
    "\n",
    "\t\t\tp1 = np.expand_dims(pat[0],-1)\n",
    "\t\t\tp2 = np.expand_dims(pat[1],-1)\n",
    "\t\t\tdata = np.concatenate((p1,p2),-1)\n",
    "\t\t\tclean_ims.append(data)\n",
    "\t\t\tpix_dimensions.append(nii_img.header['pixdim'])\n",
    "\t\t\t\n",
    "\t\treturn clean_ims, pix_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes directory to store data\n",
    "if not os.path.exists('./seg_data'):\n",
    "    os.makedirs('./seg_data')\n",
    "\n",
    "#Set number of HVSMR datasets to process\n",
    "HVSMR_No = 1\n",
    "\n",
    "#Set output data size\n",
    "z=112\n",
    "x=256\n",
    "y=128\n",
    "\n",
    "#Loop for data generation\n",
    "for pat in range(HVSMR_No):\n",
    "    \n",
    "\tdata, pix_dimensions_1 = load_data_samples(pat)\n",
    "\n",
    "\tsegmentations = []\n",
    "\tfor i in range(8):\n",
    "\t\tseg = (data[0][:,:,:,1]==(i+1))\n",
    "\t\tsegmentations.append(seg)\n",
    "\tsegmentations = np.array(segmentations)\n",
    "\tsegmentations = np.transpose(segmentations,(1,2,3,0))\n",
    "\tim = np.expand_dims(norm(data[0][:,:,:,0]),-1)\n",
    "\ttemp = np.concatenate((im,segmentations),-1)\n",
    "\t\n",
    "\tsf_x = pix_dimensions_1[0][3]\n",
    "\tsf_y = pix_dimensions_1[0][2]\n",
    "\tsf_z = pix_dimensions_1[0][1]\n",
    "\n",
    "\ttemp = temp[::-1,:,:,:]\n",
    "\n",
    "\t#Rescale to 1.5mm isotropic\n",
    "\trescaled_temp = []\n",
    "\tfor channel in range(temp.shape[-1]):\n",
    "\t\trescaled = skimage.transform.rescale(temp[...,channel], scale=[sf_x/1.5,sf_y/1.5,sf_z/1.5], order=3,anti_aliasing= True,preserve_range=True, mode ='constant',cval=0)\n",
    "\t\trescaled_temp.append(rescaled)\n",
    "  \n",
    "\trescaled = np.array(rescaled_temp)\n",
    "\trescaled = np.transpose(rescaled,(1,2,3,0))\n",
    "\n",
    "\t#Threshold to keep masks binary\n",
    "\trounded_data = []\n",
    "\tfor i in range(8):\n",
    "\t\tint_seg = rescaled[:,:,:,i+1] > 0.2\n",
    "\t\trounded_data.append(int_seg)\n",
    "\t\n",
    "\trounded_data = np.array(rounded_data)\n",
    "\trounded_data = np.transpose(rounded_data,(1,2,3,0))\n",
    "\ttemp = np.concatenate((rescaled[...,:1],rounded_data),-1)\n",
    "\n",
    "\t#Crop or pad to desired shape\n",
    "\ty_mid = find_com(temp[int(np.rint(temp.shape[0]/2)),:,:,0])[0]\n",
    "\tz_com = find_com(temp[:,:,int(y_mid),0])[1]\n",
    "\tcropped_vol= []\n",
    "\tseg_cropped_vol = []\n",
    "\t\n",
    "\tstart = z_com - z/2\n",
    "\tempty_slice = np.zeros((256,128,8))\n",
    "\tempty_slice_1 = np.zeros((256,128,1))\n",
    "\tif start + z > temp.shape[0]:\n",
    "\t\tstart = temp.shape[0]-z\n",
    "\t\tmissing = 0\n",
    "\tif start < 0:\n",
    "\t\tstart = 0\n",
    "\t\tmissing = z - temp.shape[0]\n",
    "\telse:\n",
    "\t\tmissing = 0\n",
    "\n",
    "\tif missing!=0:\n",
    "\t\tpad_number_1 = int(np.rint(missing/2))\n",
    "\t\tfor j in range(pad_number_1):\n",
    "\t\t\tcropped_vol.append(empty_slice_1)\n",
    "\t\t\tseg_cropped_vol.append(empty_slice)\n",
    "\tfor i in range(temp.shape[0]):\n",
    "\t\tslice = temp[i,...,:1]\n",
    "\t\tseg_slice = temp[i,...,1:]\n",
    "\t\tif start <= i < start+z:\n",
    "\t\t\tpad_x = x-slice.shape[0]\n",
    "\t\t\tpad_y = y - slice.shape[1]\n",
    "\t\t\tif pad_x > 0 and pad_y >0:\n",
    "\t\t\t\tslice = np.pad(slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='constant')\n",
    "\t\t\telif pad_x > 0:\n",
    "\t\t\t\tslice = np.pad(slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(0,0),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((int(np.floor(pad_x/2)),int(np.ceil(pad_x/2))),(0,0),(0,0)),mode='constant')\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\telif pad_y > 0:\n",
    "\t\t\t\tslice = np.pad(slice,((0,0),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='symmetric')\n",
    "\t\t\t\tseg_slice = np.pad(seg_slice,((0,0),(int(np.floor(pad_y/2)),int(np.ceil(pad_y/2))),(0,0)),mode='constant')\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\telse:\n",
    "\t\t\t\tslice = tf.image.resize_with_crop_or_pad(slice,x,y)\n",
    "\t\t\t\tseg_slice = tf.image.resize_with_crop_or_pad(seg_slice,x,y)\n",
    "\t\t\tcropped_vol.append(slice)\n",
    "\t\t\tseg_cropped_vol.append(seg_slice)\n",
    "\tif missing!=0:\n",
    "\t\tpad_number_2 = missing - pad_number_1\n",
    "\t\tfor j in range(pad_number_2):\n",
    "\t\t\tcropped_vol.append(empty_slice_1)\n",
    "\t\t\tseg_cropped_vol.append(empty_slice)\n",
    "\n",
    "\tcropped_vol_1 = np.array(cropped_vol)\n",
    "\tseg_cropped_vol_1 = np.array(seg_cropped_vol)\n",
    " \n",
    "\t#Fill LV and RV masks\n",
    "\tnew_masks = []\n",
    "\tfor i in range(2):\n",
    "\t\tch = seg_cropped_vol_1[...,i]\n",
    "\t\tch = tf.expand_dims(tf.expand_dims(tf.cast(ch,tf.float32),0),-1)\n",
    "\t\tnew_ch = fill_mask_3d(ch,iter=8)\n",
    "\t\tnew_masks.append(new_ch[0,...])\n",
    "\tfinal = np.array(new_masks)\n",
    "\tfinal = np.transpose(final,(4,1,2,3,0))\n",
    " \n",
    "\tcropped_vol_1 = apply_clahe(cropped_vol_1) #CLAHE\n",
    "\tout = np.concatenate((cropped_vol_1[...,:1],final[0,...],seg_cropped_vol_1[...,3:4],seg_cropped_vol_1[...,4:5],seg_cropped_vol_1[...,5:6],seg_cropped_vol_1[...,6:7]),-1)\n",
    "\n",
    "\tnp.save(f'./seg_data/High_Res_HVSMR_NoAug_{pat}.npy', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
